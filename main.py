import argparse
import logging
import os
import socket
import sys
import time
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime

import torch
# add the FedML root directory to the python path

from utils.logger import logging_config
from configs import get_cfg

from algorithms_standalone.fedavg.FedAVGManager import FedAVGManager
from algorithms_standalone.fedprox.FedProxManager import FedProxManager
from algorithms_standalone.pfedme.PFedMeManager import PFedMeManager
from algorithms_standalone.basePS.basePSmanager import BasePSManager

from utils.set import *

sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), "../../../")))
sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), "../../")))


def add_args(parser):
    """
    parser : argparse.ArgumentParser
    return a parser added with args required by fit
    """
    parser.add_argument("--config_file", default=None, type=str)
    parser.add_argument("--algorithm", default="FedAvg", type=str, 
                       help="Algorithm to run: FedAvg, FedProx, PFedMe, FedNova, FedFed")
    parser.add_argument("--quick_test", action="store_true", 
                       help="Enable quick test mode")
    parser.add_argument("--full_validation", action="store_true", 
                       help="Enable full validation")
    parser.add_argument("--output_dir", default="./results", type=str,
                       help="Directory to save results")
    parser.add_argument("opts", help="Modify config options using the command-line",
                        default=None, nargs=argparse.REMAINDER)

    args = parser.parse_args()
    return args


class TrainingProgressTracker:
    """è®­ç»ƒè¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, total_rounds, output_dir, algorithm_name):
        self.total_rounds = total_rounds
        self.output_dir = output_dir
        self.algorithm_name = algorithm_name
        self.start_time = time.time()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è®­ç»ƒå†å²è®°å½•
        self.train_history = {
            'rounds': [],
            'train_loss': [],
            'train_acc': [],
            'test_loss': [],
            'test_acc': [],
            'time_per_round': []
        }
        
        logging.info(f"=== å¼€å§‹è®­ç»ƒ {algorithm_name} ç®—æ³• ===")
        logging.info(f"æ€»è½®æ•°: {total_rounds}")
        logging.info(f"ç»“æœä¿å­˜ç›®å½•: {output_dir}")

    def update_round(self, round_idx):
        """æ›´æ–°å½“å‰è½®æ¬¡"""
        self.current_round = round_idx
        progress = (round_idx + 1) / self.total_rounds * 100
        logging.info(f"ğŸ”„ å¼€å§‹ç¬¬ {round_idx + 1}/{self.total_rounds} è½®è®­ç»ƒ ({progress:.1f}%)")

    def record_round_results(self, round_idx, train_loss, train_acc, test_loss, test_acc):
        """è®°å½•è½®æ¬¡ç»“æœ"""
        current_time = time.time()
        elapsed_time = current_time - self.start_time
        time_per_round = elapsed_time / (round_idx + 1)
        remaining_time = time_per_round * (self.total_rounds - round_idx - 1)
        
        # è®°å½•å†å²
        self.train_history['rounds'].append(round_idx + 1)
        self.train_history['train_loss'].append(train_loss)
        self.train_history['train_acc'].append(train_acc)
        self.train_history['test_loss'].append(test_loss)
        self.train_history['test_acc'].append(test_acc)
        self.train_history['time_per_round'].append(time_per_round)
        
        # æ˜¾ç¤ºè¿›åº¦
        logging.info(f"ğŸ“Š ç¬¬ {round_idx + 1} è½®ç»“æœ:")
        logging.info(f"   ğŸ¯ è®­ç»ƒ - æŸå¤±: {train_loss:.4f}, ç²¾åº¦: {train_acc:.4f}")
        logging.info(f"   ğŸ¯ æµ‹è¯• - æŸå¤±: {test_loss:.4f}, ç²¾åº¦: {test_acc:.4f}")
        logging.info(f"   â±ï¸  å·²ç”¨æ—¶é—´: {elapsed_time/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {remaining_time/60:.1f}åˆ†é’Ÿ")
        logging.info("-" * 60)

    def finish_training(self):
        """å®Œæˆè®­ç»ƒ"""
        total_time = time.time() - self.start_time
        logging.info(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")

    def save_results(self):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è®­ç»ƒå†å²åˆ°JSONæ–‡ä»¶
        results_file = os.path.join(
            self.output_dir, f"{self.algorithm_name}_results_{timestamp}.json")
        with open(results_file, 'w') as f:
            json.dump(self.train_history, f, indent=2)
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self._plot_training_curves(timestamp)
        
        # ä¿å­˜æœ€ç»ˆç»“æœæ‘˜è¦
        self._save_summary(timestamp)
        
        logging.info(f"è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")

    def _plot_training_curves(self, timestamp):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        plt.figure(figsize=(15, 10))
        
        # æŸå¤±æ›²çº¿
        plt.subplot(2, 2, 1)
        plt.plot(self.train_history['rounds'], self.train_history['train_loss'], 
                'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        plt.plot(self.train_history['rounds'], self.train_history['test_loss'], 
                'r-', label='æµ‹è¯•æŸå¤±', linewidth=2)
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('æŸå¤±')
        plt.title(f'{self.algorithm_name} - æŸå¤±æ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ç²¾åº¦æ›²çº¿
        plt.subplot(2, 2, 2)
        plt.plot(self.train_history['rounds'], self.train_history['train_acc'], 
                'b-', label='è®­ç»ƒç²¾åº¦', linewidth=2)
        plt.plot(self.train_history['rounds'], self.train_history['test_acc'], 
                'r-', label='æµ‹è¯•ç²¾åº¦', linewidth=2)
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('ç²¾åº¦')
        plt.title(f'{self.algorithm_name} - ç²¾åº¦æ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # æ¯è½®æ—¶é—´
        plt.subplot(2, 2, 3)
        plt.plot(self.train_history['rounds'], self.train_history['time_per_round'], 
                'g-', linewidth=2)
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('æ—¶é—´ (ç§’)')
        plt.title(f'{self.algorithm_name} - æ¯è½®è®­ç»ƒæ—¶é—´')
        plt.grid(True, alpha=0.3)
        
        # ç²¾åº¦å¯¹æ¯”
        plt.subplot(2, 2, 4)
        final_train_acc = self.train_history['train_acc'][-1] if self.train_history['train_acc'] else 0
        final_test_acc = self.train_history['test_acc'][-1] if self.train_history['test_acc'] else 0
        plt.bar(['è®­ç»ƒç²¾åº¦', 'æµ‹è¯•ç²¾åº¦'], [final_train_acc, final_test_acc], 
               color=['blue', 'red'], alpha=0.7)
        plt.ylabel('ç²¾åº¦')
        plt.title(f'{self.algorithm_name} - æœ€ç»ˆç²¾åº¦å¯¹æ¯”')
        plt.ylim(0, 1)
        
        plt.tight_layout()
        plot_file = os.path.join(
            self.output_dir, f"{self.algorithm_name}_curves_{timestamp}.png")
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        plt.close()

    def _save_summary(self, timestamp):
        """ä¿å­˜ç»“æœæ‘˜è¦"""
        total_time = time.time() - self.start_time
        
        summary = {
            'algorithm': self.algorithm_name,
            'timestamp': timestamp,
            'total_rounds': self.total_rounds,
            'total_time_minutes': total_time / 60,
            'final_train_accuracy': self.train_history['train_acc'][-1] if self.train_history['train_acc'] else 0,
            'final_test_accuracy': self.train_history['test_acc'][-1] if self.train_history['test_acc'] else 0,
            'best_test_accuracy': max(self.train_history['test_acc']) if self.train_history['test_acc'] else 0,
            'final_train_loss': self.train_history['train_loss'][-1] if self.train_history['train_loss'] else 0,
            'final_test_loss': self.train_history['test_loss'][-1] if self.train_history['test_loss'] else 0,
            'avg_time_per_round': np.mean(self.train_history['time_per_round']) if self.train_history['time_per_round'] else 0
        }
        
        summary_file = os.path.join(
            self.output_dir, f"{self.algorithm_name}_summary_{timestamp}.json")
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)


def run_algorithm(cfg, device, algorithm_name, output_dir):
    """è¿è¡ŒæŒ‡å®šçš„è”é‚¦å­¦ä¹ ç®—æ³•"""
    
    # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
    tracker = TrainingProgressTracker(
        cfg.comm_round, output_dir, algorithm_name)
    
    # æ ‡å‡†åŒ–ç®—æ³•åç§°ï¼ˆæ”¯æŒå°å†™è¾“å…¥ï¼‰
    algorithm_name_lower = algorithm_name.lower()
    
    # é€‰æ‹©ç®—æ³•ç®¡ç†å™¨
    if algorithm_name_lower in ['fedavg', 'FedAvg']:
        manager = FedAVGManager(device, cfg)
    elif algorithm_name_lower in ['fedprox', 'FedProx']:
        manager = FedProxManager(device, cfg)
    elif algorithm_name_lower in ['pfedme', 'PFedMe']:
        manager = PFedMeManager(device, cfg)
    elif algorithm_name_lower in ['fedfed', 'FedFed']:
        manager = FedAVGManager(device, cfg)  # FedFedåŸºäºFedAvgå®ç°
    else:
        raise NotImplementedError(f"Algorithm {algorithm_name} not supported. "
                                f"Supported algorithms: FedAvg, FedProx, PFedMe, FedFed")
    
    # å°è¯•ä½¿ç”¨å¸¦è¿›åº¦è·Ÿè¸ªçš„è®­ç»ƒæ–¹æ³•
    try:
        if hasattr(manager, 'train_with_progress'):
            manager.train_with_progress(tracker)
        else:
            logging.warning("ä½¿ç”¨åŸå§‹è®­ç»ƒæ–¹æ³•ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†è¿›åº¦")
            manager.train()
    except Exception as e:
        logging.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise
    
    # å®Œæˆè®­ç»ƒå¹¶ç”Ÿæˆç»“æœ
    tracker.finish_training()
    
    return tracker


if __name__ == "__main__":
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser()
    args = add_args(parser)
    
    # è®¾ç½®é…ç½®
    cfg = get_cfg()
    cfg.setup(args)
    cfg.mode = 'standalone'
    cfg.server_index = -1
    cfg.client_index = -1
    
    # è®¾ç½®ç®—æ³•ç±»å‹
    if hasattr(args, 'algorithm'):
        cfg.algorithm = args.algorithm
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick_test:
        cfg.comm_round = 3
        cfg.client_num_in_total = 3
        cfg.client_num_per_round = 2
        cfg.global_epochs_per_round = 1
        logging.info("å¯ç”¨å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    
    # è®¾ç½®éªŒè¯æ¨¡å¼
    cfg.full_validation = args.full_validation
    
    seed = cfg.seed
    process_id = 0
    
    # æ˜¾ç¤ºé…ç½®
    logging.info(dict(cfg))
    
    # è®¾ç½®è¿›ç¨‹å
    str_process_name = cfg.algorithm + " (standalone):" + str(process_id)
    
    # é…ç½®æ—¥å¿—
    logging_config(args=cfg, process_id=process_id)
    
    hostname = socket.gethostname()
    logging.info("#############process ID = " + str(process_id) +
                ", host name = " + hostname + "########" +
                ", process ID = " + str(os.getpid()))

    # è®¾ç½®éšæœºç§å­
    set_random_seed(seed) 
    torch.backends.cudnn.deterministic = True

    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda:" + str(cfg.gpu_index) if torch.cuda.is_available() else "cpu")
    
    # é…ç½®wandb
    if cfg.record_tool == 'wandb' and cfg.wandb_record:
        import wandb
        wandb.init(config=args, name=f'{cfg.algorithm}_test',
                   project='FedFed_Yummly28k')
    else: 
        os.environ['WANDB_MODE'] = 'dryrun'

    # è¿è¡Œç®—æ³•
    tracker = run_algorithm(cfg, device, cfg.algorithm, args.output_dir)
    
    logging.info("=== è®­ç»ƒå®Œæˆ ===")
    logging.info(f"æœ€ç»ˆæµ‹è¯•ç²¾åº¦: {tracker.train_history['test_acc'][-1] if tracker.train_history['test_acc'] else 0:.4f}")
    logging.info(f"æ€»è®­ç»ƒæ—¶é—´: {(time.time() - tracker.start_time)/60:.1f}åˆ†é’Ÿ")








